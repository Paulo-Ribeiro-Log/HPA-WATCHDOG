# CLAUDE.md

Este arquivo fornece orientaÃ§Ãµes ao Claude Code (claude.ai/code) ao trabalhar com o cÃ³digo neste repositÃ³rio.

## VisÃ£o Geral do Projeto

**HPA Watchdog** Ã© um sistema autÃ´nomo de monitoramento de Horizontal Pod Autoscalers (HPAs) do Kubernetes em mÃºltiplos clusters. Ele oferece uma TUI (Terminal UI) rica construÃ­da com Bubble Tea e Lipgloss, fornecendo monitoramento em tempo real, detecÃ§Ã£o de anomalias e gerenciamento centralizado de alertas.

**Status**: ğŸŸ¢ Fase de desenvolvimento - Componentes principais implementados
**Meta**: Monitoramento de HPAs multi-cluster com integraÃ§Ã£o Prometheus + Alertmanager

### Status da ImplementaÃ§Ã£o
- âœ… **Camada de Armazenamento**: Cache de sÃ©ries temporais em memÃ³ria + persistÃªncia em SQLite (retenÃ§Ã£o de 24h)
- âœ… **Camada de AnÃ¡lise**: Fase 1 (estado persistente) + Fase 2 (mudanÃ§as sÃºbitas) - 10 tipos de anomalia
- âœ… **Camada de Cliente K8s**: Coleta de HPA e criaÃ§Ã£o de snapshots
- âœ… **Camada de Cliente Prometheus**: Enriquecimento de mÃ©tricas com consultas PromQL
- âœ… **Camada de Coleta**: OrquestraÃ§Ã£o unificada de K8s + Prometheus + Analyzer
- âœ… **Camada de ConfiguraÃ§Ã£o**: Sistema de configuraÃ§Ã£o baseado em YAML
- âœ… **Camada de PersistÃªncia**: SQLite com auto-save/load e limpeza
- âœ… **Camada TUI**: 7 views implementadas (Dashboard, Alertas, Clusters, HistÃ³rico, Stress Test, RelatÃ³rio Final, Detalhes)
- âœ… **Stress Test Mode**: Baseline capture, comparaÃ§Ã£o em tempo real, relatÃ³rio final automatizado
- âš ï¸ **Camada Alertmanager**: Opcional (nÃ£o crÃ­tica para o MVP)

## Filosofia Central: KISS (Keep It Simple, Stupid)

**IMPORTANTE**: Este projeto segue o princÃ­pio KISS Ã  risca. Ao desenvolver:

- **Prefira simplicidade a esperteza** - CÃ³digo direto supera soluÃ§Ãµes "inteligentes"
- **Evite superengenharia** - Construa o que Ã© necessÃ¡rio agora, nÃ£o o que pode ser necessÃ¡rio depois
- **Evite otimizaÃ§Ã£o prematura** - FaÃ§a funcionar primeiro, otimize apenas se for realmente necessÃ¡rio
- **Use tecnologia entediante** - Bibliotecas comprovadas em vez de novidades/ tendÃªncias
- **Claro em vez de conciso** - CÃ³digo legÃ­vel vence cÃ³digo curto
- **Uma responsabilidade por componente** - Cada mÃ³dulo deve fazer uma coisa bem
- **Falhe rÃ¡pido e de forma evidente** - Melhor travar com um erro claro do que falhar silenciosamente
- **ConfiguraÃ§Ã£o antes de cÃ³digo** - Prefira tornar o comportamento configurÃ¡vel a codificar lÃ³gica complexa fixa

### KISS na PrÃ¡tica

- **Loop de monitoramento**: Goroutine simples por cluster, sem agendamento complexo
- **Armazenamento de dados**: Abordagem hÃ­brida - RAM (acesso rÃ¡pido de 5min) + SQLite (persistÃªncia de 24h)
- **CorrelaÃ§Ã£o de alertas**: Agrupamento bÃ¡sico por cluster/namespace/HPA - sem complexidade de ML/IA
- **TUI**: PadrÃµes padrÃ£o do Bubble Tea - nada de frameworks personalizados
- **Tratamento de erros**: Mensagens claras, degradaÃ§Ã£o graciosa - sem falhas silenciosas
- **PersistÃªncia**: Auto-save para SQLite (assÃ­ncrono), auto-load no startup, auto-cleanup de dados antigos

Se uma soluÃ§Ã£o parecer complexa, provavelmente Ã©. DÃª um passo atrÃ¡s e encontre a abordagem mais simples.

## Arquitetura

### Coleta de Dados em TrÃªs Camadas

1. **Kubernetes API** (client-go): ConfiguraÃ§Ã£o do HPA, contagem de rÃ©plicas, informaÃ§Ãµes de deployment, eventos
2. **Prometheus API**: MÃ©tricas (CPU/MemÃ³ria/Rede) e anÃ¡lise temporal com PromQL
3. **Alertmanager API**: AgregaÃ§Ã£o de alertas existentes e gerenciamento de silÃªncios

### Abordagem HÃ­brida

- **API do K8s**: Dados de configuraÃ§Ã£o e estado (rÃ©plicas mÃ­n./mÃ¡x., rÃ©plicas atuais/desejadas)
- **Prometheus**: Fonte principal de mÃ©tricas com histÃ³rico nativo e mÃ©tricas ricas (CPU, MemÃ³ria, taxa de requisiÃ§Ãµes, taxa de erros, latÃªncia P95)
- **Alertmanager**: Fonte principal de alertas vindos de regras Prometheus existentes (70% dos alertas)
- **Watchdog Analyzer**: DetecÃ§Ã£o de anomalias complementar para padrÃµes nÃ£o cobertos pelas consultas PromQL simples (30% dos alertas)

## Modelo de Dados Central

### HPASnapshot
Snapshot estendido que captura tanto o estado do K8s quanto mÃ©tricas do Prometheus:
- Dados do K8s: ConfiguraÃ§Ã£o do HPA, rÃ©plicas, requests/limits de recursos, status
- Dados do Prometheus: MÃ©tricas atuais, histÃ³rico de 5 minutos, mÃ©tricas estendidas (taxa de requisiÃ§Ãµes, taxa de erros, latÃªncia)
- Indicador de fonte de dados: Prometheus (preferencial), Metrics-Server (fallback) ou hÃ­brido

### UnifiedAlert
Combina alertas do Alertmanager e da detecÃ§Ã£o prÃ³pria do Watchdog:
- Rastreamento da origem (Alertmanager vs Watchdog)
- Enriquecimento com HPASnapshot e AlertContext
- CorrelaÃ§Ã£o com alertas relacionados
- Suporte a silÃªncio e confirmaÃ§Ã£o

## Estrutura do Projeto

```
hpa-watchdog/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go                    # Ponto de entrada
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ analyzer/                  # âœ… IMPLEMENTADO
â”‚   â”‚   â”œâ”€â”€ detector.go            # Detector de anomalias com 10 tipos (Fase 1 + Fase 2)
â”‚   â”‚   â”œâ”€â”€ detector_test.go       # 12 testes unitÃ¡rios (Fase 1)
â”‚   â”‚   â”œâ”€â”€ sudden_changes_test.go # 8 testes unitÃ¡rios (Fase 2)
â”‚   â”‚   â””â”€â”€ README.md              # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ storage/                   # âœ… IMPLEMENTADO
â”‚   â”‚   â”œâ”€â”€ cache.go               # Cache de sÃ©ries temporais com integraÃ§Ã£o de persistÃªncia
â”‚   â”‚   â”œâ”€â”€ cache_test.go          # 12 testes do cache
â”‚   â”‚   â”œâ”€â”€ persistence.go         # Camada de persistÃªncia com SQLite
â”‚   â”‚   â”œâ”€â”€ persistence_test.go    # 8 testes de persistÃªncia
â”‚   â”‚   â””â”€â”€ README.md              # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ models/                    # âœ… IMPLEMENTADO
â”‚   â”‚   â””â”€â”€ types.go               # HPASnapshot, TimeSeriesData, HPAStats, GetPrevious()
â”‚   â”œâ”€â”€ monitor/                   # ğŸ”„ TODO
â”‚   â”‚   â”œâ”€â”€ collector.go           # Coletor unificado (K8s + Prometheus + Alertmanager)
â”‚   â”‚   â”œâ”€â”€ analyzer.go            # DetecÃ§Ã£o de anomalias
â”‚   â”‚   â””â”€â”€ alerter.go             # Sistema de alertas
â”‚   â”œâ”€â”€ prometheus/                # ğŸ”„ TODO
â”‚   â”‚   â”œâ”€â”€ client.go              # Wrapper da API do Prometheus
â”‚   â”‚   â”œâ”€â”€ queries.go             # Consultas PromQL predefinidas
â”‚   â”‚   â””â”€â”€ discovery.go           # Descoberta automÃ¡tica de endpoints
â”‚   â”œâ”€â”€ alertmanager/              # ğŸ”„ TODO
â”‚   â”‚   â””â”€â”€ client.go              # Wrapper da API do Alertmanager
â”‚   â”œâ”€â”€ config/                    # ğŸ”„ TODO
â”‚   â”‚   â”œâ”€â”€ loader.go              # Carregamento de configuraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ thresholds.go          # Gerenciamento de thresholds
â”‚   â”‚   â””â”€â”€ clusters.go            # Descoberta de clusters
â”‚   â””â”€â”€ tui/                       # ğŸ”„ TODO
â”‚       â”œâ”€â”€ app.go                 # Aplicativo principal Bubble Tea
â”‚       â”œâ”€â”€ views.go               # RenderizaÃ§Ã£o das views
â”‚       â”œâ”€â”€ handlers.go            # Manipuladores de eventos
â”‚       â”œâ”€â”€ components/            # Componentes de UI (dashboard, alertas, grÃ¡ficos, config)
â”‚       â””â”€â”€ styles.go              # Estilos do Lipgloss
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ watchdog.yaml              # ConfiguraÃ§Ã£o padrÃ£o
â””â”€â”€ HPA_WATCHDOG_*.md              # Documentos de especificaÃ§Ã£o
```

## Comandos de Desenvolvimento

### Build
```bash
# Compilar o binÃ¡rio
go build -o build/hpa-watchdog ./cmd/main.go

# Compilar com informaÃ§Ã£o de versÃ£o
go build -ldflags "-X main.Version=v1.0.0" -o build/hpa-watchdog ./cmd/main.go
```

### ExecuÃ§Ã£o
```bash
# Executar com a configuraÃ§Ã£o padrÃ£o
./build/hpa-watchdog

# Executar com uma configuraÃ§Ã£o personalizada
./build/hpa-watchdog --config /caminho/para/watchdog.yaml

# Modo debug (logs verbosos)
./build/hpa-watchdog --debug
```

### Testes
```bash
# Executar todos os testes
go test ./...

# Testar um pacote especÃ­fico
go test ./internal/monitor/...

# Testar com cobertura
go test -cover ./...

# Testes de integraÃ§Ã£o (exige acesso a um cluster K8s)
go test ./tests/integration/...
```

### ValidaÃ§Ã£o da ConfiguraÃ§Ã£o
```bash
# Validar arquivo de configuraÃ§Ã£o
./build/hpa-watchdog validate --config configs/watchdog.yaml
```

## DependÃªncias Principais

- **k8s.io/client-go@v0.31.4**: Cliente da API do Kubernetes
- **github.com/charmbracelet/bubbletea@v0.24.2**: Framework de TUI
- **github.com/charmbracelet/lipgloss@v1.1.0**: EstilizaÃ§Ã£o de terminal
- **github.com/prometheus/client_golang**: Cliente da API do Prometheus
- **github.com/spf13/viper**: Gerenciamento de configuraÃ§Ã£o
- **github.com/guptarohit/asciigraph**: GrÃ¡ficos ASCII para mÃ©tricas
- **github.com/rs/zerolog**: Logging estruturado
- **github.com/mattn/go-sqlite3**: PersistÃªncia em SQLite (necessÃ¡ria em produÃ§Ã£o)

## Consultas Importantes de Prometheus

### Uso de CPU (alvo do HPA)
```promql
sum(rate(container_cpu_usage_seconds_total{namespace="{namespace}",pod=~"{pod_selector}"}[1m])) /
sum(kube_pod_container_resource_requests{namespace="{namespace}",pod=~"{pod_selector}",resource="cpu"}) * 100
```

### HistÃ³rico de RÃ©plicas
```promql
kube_horizontalpodautoscaler_status_current_replicas{namespace="{namespace}",horizontalpodautoscaler="{name}"}[5m]
```

### Taxa de RequisiÃ§Ãµes
```promql
sum(rate(http_requests_total{namespace="{namespace}",service="{service}"}[1m]))
```

### Taxa de Erros
```promql
sum(rate(http_requests_total{namespace="{namespace}",service="{service}",status=~"5.."}[1m])) /
sum(rate(http_requests_total{namespace="{namespace}",service="{service}"}[1m])) * 100
```

## Sistema de ConfiguraÃ§Ã£o

### Arquivo de ConfiguraÃ§Ã£o: `configs/watchdog.yaml`

SeÃ§Ãµes principais:
- **monitoring**: Intervalos de varredura, definiÃ§Ãµes de Prometheus/Alertmanager, descoberta automÃ¡tica
- **clusters**: Descoberta e filtragem de clusters
- **storage**: PersistÃªncia opcional com SQLite
- **alerts**: Prioridade da fonte, deduplicaÃ§Ã£o, correlaÃ§Ã£o
- **thresholds**: Limites de CPU/MemÃ³ria, deltas de rÃ©plicas, mÃ©tricas estendidas
- **ui**: Taxa de atualizaÃ§Ã£o, tema, sons

### Descoberta AutomÃ¡tica

- **Clusters**: Descobre a partir do kubeconfig ou `clusters-config.json`
- **Prometheus**: Testa padrÃµes comuns de serviÃ§o no namespace de monitoramento
- **Alertmanager**: Testa padrÃµes comuns de serviÃ§o no namespace de monitoramento
- **Fallback**: Usa o Metrics-Server do Kubernetes se o Prometheus nÃ£o estiver disponÃ­vel

## EstratÃ©gia de PersistÃªncia de Dados

### Armazenamento HÃ­brido: RAM + SQLite âœ…

**Por que hÃ­brido?**
- **RAM (5min)**: Acesso ultrarrÃ¡pido para comparaÃ§Ãµes e detecÃ§Ã£o de anomalias
- **SQLite (24h)**: PersistÃªncia que sobrevive a reinicializaÃ§Ãµes e permite anÃ¡lise histÃ³rica

### ImplementaÃ§Ã£o (`internal/storage/`)

#### Cache em MemÃ³ria (TimeSeriesCache)
```go
cache := storage.NewTimeSeriesCache(&CacheConfig{
    MaxDuration:  5 * time.Minute,  // Janela deslizante
    ScanInterval: 30 * time.Second, // ~10 snapshots por HPA
})
```

- **Acesso rÃ¡pido**: Busca O(1) por cluster/namespace/nome
- **Limpeza automÃ¡tica**: Remove snapshots com mais de 5 minutos
- **EstatÃ­sticas**: TendÃªncias prÃ©-calculadas de CPU/MemÃ³ria, variaÃ§Ãµes de rÃ©plicas
- **Thread-safe**: sync.RWMutex para acesso concorrente

#### PersistÃªncia em SQLite
```go
persist, _ := storage.NewPersistence(&PersistenceConfig{
    Enabled:     true,
    DBPath:      "~/.hpa-watchdog/snapshots.db",
    MaxAge:      24 * time.Hour,
    AutoCleanup: true,
})

cache.SetPersistence(persist)  // Auto-save habilitado!
```

**Recursos**:
- **Auto-save**: Cada snapshot adicionado ao cache Ã© salvo em SQLite (assÃ­ncrono)
- **Auto-load**: No startup, carrega os Ãºltimos 5 minutos do SQLite para a RAM
- **Auto-cleanup**: Remove snapshots com mais de 24h
- **OperaÃ§Ãµes em lote**: Inserts/consultas em massa eficientes
- **Schema**: Tabela simples com serializaÃ§Ã£o JSON dos snapshots

**Schema do Banco**:
```sql
CREATE TABLE snapshots (
    cluster TEXT,
    namespace TEXT,
    hpa_name TEXT,
    timestamp DATETIME,
    data TEXT  -- HPASnapshot completo como JSON
)
```

**Estimativas de armazenamento** (24 clusters, 2400 HPAs):
- MemÃ³ria: ~12 MB (janela de 5min)
- SQLite: ~3,3 GB (retenÃ§Ã£o de 24h, auto-cleanup)
- Tempo de varredura: <5s por cluster (2880 varreduras/dia)

### BenefÃ­cios da PersistÃªncia para Multi-Cluster

1. **Sobrevive a reinicializaÃ§Ãµes**: Sem perda de dados quando o HPA Watchdog reinicia
2. **DetecÃ§Ã£o imediata**: Detecta mudanÃ§as sÃºbitas desde o primeiro scan (carrega estado anterior)
3. **AnÃ¡lise histÃ³rica**: 24h de dados para anÃ¡lise de tendÃªncias e depuraÃ§Ã£o
4. **Baixo uso de memÃ³ria**: Apenas 5min em RAM, restante no SQLite
5. **Performance**: Saves assÃ­ncronos nÃ£o bloqueiam o loop de monitoramento

## Loop de Monitoramento

Cada cluster executa uma goroutine independente:
1. Lista namespaces (pula namespaces de sistema)
2. Para cada namespace, lista HPAs
3. Para cada HPA:
   - ObtÃ©m a configuraÃ§Ã£o via API do K8s
   - Consulta mÃ©tricas no Prometheus (atual + histÃ³rico de 5min)
   - Cria o HPASnapshot
   - Armazena no cache de sÃ©ries temporais â†’ **Auto-salvo no SQLite**
4. Sincroniza alertas do Alertmanager
5. Analisa snapshots em busca de anomalias (persistentes e sÃºbitas)
6. Envia alertas unificados para a TUI via canais
7. Dorme atÃ© o prÃ³ximo intervalo de varredura

**Na inicializaÃ§Ã£o**: Carrega os Ãºltimos 5 minutos do SQLite â†’ Pronto para detectar mudanÃ§as imediatamente!

## Modo Stress Test

O HPA Watchdog possui um modo especializado para testes de carga e validaÃ§Ã£o de configuraÃ§Ãµes de HPA:

### Funcionalidades
1. **Baseline Capture**: Captura estado PRE (rÃ©plicas, CPU, memory) antes do teste iniciar
2. **Monitoramento em Tempo Real**: Dashboard interativo com grÃ¡ficos de CPU/Memory (timezone GMT-3)
3. **ComparaÃ§Ã£o AutomÃ¡tica**: Compara cada scan com baseline e detecta desvios
4. **TÃ©rmino AutomÃ¡tico**: Para automaticamente ao fim da duraÃ§Ã£o configurada
5. **RelatÃ³rio Final AutomÃ¡tico**: Gera e exibe relatÃ³rio completo ao tÃ©rmino

### Fluxo do Stress Test
```
Setup â†’ Baseline Capture (30min histÃ³rico) â†’ Teste Inicia â†’ Scans PeriÃ³dicos
â†’ ComparaÃ§Ã£o com Baseline â†’ TÃ©rmino (automÃ¡tico ou manual) â†’ RelatÃ³rio Final
```

### RelatÃ³rio Final
Gerado automaticamente ao tÃ©rmino e exibido na **ViewStressReport**:
- **Badge PASS/FAIL**: Baseado em % de HPAs com problemas crÃ­ticos (<10% = PASS)
- **Barra de SaÃºde**: VisualizaÃ§Ã£o percentual de HPAs saudÃ¡veis
- **Resumo Executivo**: DuraÃ§Ã£o, scans, HPAs monitorados, problemas detectados
- **MÃ©tricas de Pico**:
  - CPU MÃ¡ximo (valor, HPA, horÃ¡rio)
  - Memory MÃ¡ximo (valor, HPA, horÃ¡rio)
  - **EvoluÃ§Ã£o de RÃ©plicas**: PRE â†’ PEAK â†’ POST com % de aumento
  - Taxa de Erro MÃ¡xima (se aplicÃ¡vel)
  - LatÃªncia P95 MÃ¡xima (se aplicÃ¡vel)
- **Problemas Detectados**: Lista de Critical Issues e Warnings (top 5 cada)
- **RecomendaÃ§Ãµes**: AÃ§Ãµes priorizadas por categoria (Scaling/Resources/Config/Code/Infra)

### Controles do Stress Test
- **P**: Pausar/Retomar scan
- **Shift+R**: Reiniciar teste (mantÃ©m na view, limpa dados, recaptura baseline)
- **E**: Exportar relatÃ³rio em Markdown (TODO)
- **Shift+E**: Exportar relatÃ³rio em PDF (TODO)
- **Scroll**: Menu de seleÃ§Ã£o de HPAs com viewport para listas grandes

### StressTestMetrics
Estrutura completa (`internal/models/stresstest.go`) que captura:
- Metadados do teste (nome, duraÃ§Ã£o, status, scans)
- MÃ©tricas gerais (clusters, HPAs, problemas)
- MÃ©tricas de pico (PeakMetrics struct)
- Problemas por severidade (CriticalIssues, WarningIssues, InfoIssues)
- HPAMetrics por HPA individual
- Timeline de eventos
- RecomendaÃ§Ãµes geradas

**PersistÃªncia**: Baseline e resultados sÃ£o salvos no SQLite para anÃ¡lise posterior.

## DetecÃ§Ã£o de Anomalias

### IntegraÃ§Ã£o com Alertmanager (PrimÃ¡ria)
- Sincroniza alertas existentes via API do Alertmanager
- Filtra alertas relacionados a HPA
- Enriquece com contexto (mÃ©tricas, histÃ³rico, correlaÃ§Ã£o)
- Fornece visÃ£o centralizada multi-cluster
- Permite gerenciar silÃªncios diretamente pela TUI

### Watchdog Analyzer - Fase 1: Anomalias de Estado Persistente âœ…
O pacote analyzer (`internal/analyzer/`) implementa 5 detectores para estados problemÃ¡ticos persistentes:

| # | Anomalia | CondiÃ§Ã£o | DuraÃ§Ã£o | Status |
|---|----------|----------|---------|--------|
| 1 | **OscilaÃ§Ã£o** | >5 alteraÃ§Ãµes de rÃ©plica | 5min | âœ… Implementado |
| 2 | **No Limite** | rÃ©plicas = mÃ¡x + CPU > alvo +20% | 2min | âœ… Implementado |
| 3 | **OOMKilled** | Pod finalizado por OOM | - | ğŸ”´ Placeholder |
| 4 | **Pods NÃ£o Prontos** | Pods nÃ£o prontos | 3min | âœ… Implementado |
| 5 | **Alta Taxa de Erros** | >5% de erros 5xx (Prometheus) | 2min | âœ… Implementado |

**Testes**: 12/12 testes unitÃ¡rios aprovados (veja `internal/analyzer/detector_test.go`)

### Watchdog Analyzer - Fase 2: MudanÃ§as SÃºbitas âœ…
Detecta variaÃ§Ãµes bruscas entre scans consecutivos (comparaÃ§Ã£o scan a scan):

| # | Anomalia | CondiÃ§Ã£o | Limite | Status |
|---|----------|----------|--------|--------|
| 6 | **Pico de CPU** | CPU aumentou >50% em 1 scan | +50% | âœ… Implementado |
| 7 | **Pico de RÃ©plicas** | RÃ©plicas aumentaram em 1 scan | +3 | âœ… Implementado |
| 8 | **Pico de Erros** | Taxa de erros aumentou em 1 scan | +5% | âœ… Implementado |
| 9 | **Pico de LatÃªncia** | LatÃªncia aumentou >100% em 1 scan | +100% | âœ… Implementado |
| 10 | **Queda de CPU** | CPU caiu >50% em 1 scan | -50% | âœ… Implementado |

**Principais caracterÃ­sticas**:
- **ComparaÃ§Ã£o scan a scan**: Compara o snapshot mais recente com o anterior (sem novas consultas ao Prometheus)
- **DetecÃ§Ã£o rÃ¡pida**: Identifica mudanÃ§as sÃºbitas imediatamente (dentro de um intervalo de varredura)
- **Cache local**: Usa `GetPrevious()` de TimeSeriesData para comparaÃ§Ã£o instantÃ¢nea
- **Thresholds configurÃ¡veis**: Todos os limites de picos sÃ£o customizÃ¡veis
- **SugestÃµes de aÃ§Ã£o**: Cada anomalia inclui aÃ§Ãµes de remediaÃ§Ã£o

**Testes**: 8/8 testes unitÃ¡rios aprovados (veja `internal/analyzer/sudden_changes_test.go`)

### EstratÃ©gia de DetecÃ§Ã£o Combinada
O analyzer executa as duas fases em cada varredura:
1. **Fase 1** detecta estados problemÃ¡ticos persistentes (requer duraÃ§Ã£o)
2. **Fase 2** detecta variaÃ§Ãµes sÃºbitas (requer 2 snapshots)

Total: **10 tipos de anomalia** cobrindo tanto tendÃªncias graduais quanto mudanÃ§as abruptas.

## NavegaÃ§Ã£o da TUI

### Controles de Teclado
#### Gerais
- `Tab`: Troca de views (Dashboard, Alertas, Clusters, HistÃ³rico, Stress Test, RelatÃ³rio)
- `â†‘â†“` ou `j k`: Navega em listas (com scroll automÃ¡tico em menus grandes)
- `Enter`: Ver detalhes / Selecionar
- `H` ou `Home`: Volta para Dashboard
- `F5` ou `R`: ForÃ§ar refresh
- `Ctrl+C` ou `Q`: Sair
- `?`: Ajuda

#### Alertas
- `A`: Reconhecer alerta
- `Shift+A`: Reconhecer todos os alertas
- `S`: Silenciar alerta (cria silÃªncio no Alertmanager)
- `C`: Limpar alertas reconhecidos
- `E`: Enriquecer alerta com contexto de mÃ©tricas
- `D`: Ver detalhes do alerta

#### Stress Test
- `P`: Pausar/Retomar scan
- `Shift+R`: Reiniciar teste automaticamente (mantÃ©m na view de stress test)
- `E`: Exportar relatÃ³rio em Markdown
- `Shift+E`: Exportar relatÃ³rio em PDF

### VisÃµes (7 views implementadas)
1. **Setup**: ConfiguraÃ§Ã£o inicial interativa (clusters, modo, duraÃ§Ã£o, intervalo)
2. **Dashboard**: VisÃ£o geral multi-cluster, resumo de alertas, top clusters, anomalias recentes
3. **Alertas**: Lista detalhada de alertas com filtragem por severidade/cluster e correlaÃ§Ã£o
4. **Clusters**: Detalhamento por cluster e namespace com mÃ©tricas agregadas
5. **HistÃ³rico**: AnÃ¡lise temporal com grÃ¡ficos de CPU/Memory/RÃ©plicas (timezone GMT-3)
6. **Stress Test**: Dashboard em tempo real com baseline, grÃ¡ficos de CPU/Memory, seleÃ§Ã£o de HPAs com scroll
7. **RelatÃ³rio Final**: Resumo executivo do stress test (PASS/FAIL, mÃ©tricas de pico PREâ†’PEAKâ†’POST, recomendaÃ§Ãµes)

## CorrelaÃ§Ã£o de Alertas

O Watchdog correlaciona automaticamente alertas relacionados:
- Agrupa alertas por cluster/namespace/HPA
- Identifica causa raiz vs sintomas
- Fornece anÃ¡lise combinada envolvendo mÃºltiplos tipos de alerta
- Sugere aÃ§Ãµes de remediaÃ§Ã£o

Exemplo: Pico de CPU â†’ rÃ©plicas no limite â†’ alta taxa de erros â†’ alta latÃªncia correlacionados como um Ãºnico incidente.

## PrincÃ­pios de Design

1. **SeguranÃ§a com runes**: Use sempre `[]rune` para lidar com texto Unicode na TUI
2. **OperaÃ§Ãµes assÃ­ncronas**: Use comandos Bubble Tea para tarefas assÃ­ncronas (consultas K8s/Prometheus)
3. **Canais para atualizaÃ§Ãµes**: Goroutines de monitoramento enviam updates para a TUI via canais
4. **EstratÃ©gia de fallback**: Prometheus â†’ Metrics-Server, com degradaÃ§Ã£o graciosa
5. **Armazenamento mÃ­nimo**: Aproveite o TSDB do Prometheus em vez de caches locais pesados
6. **Somente leitura**: Sem modificaÃ§Ãµes no cluster, operaÃ§Ãµes de monitoramento seguras

## SeguranÃ§a e PermissÃµes

### RBAC necessÃ¡rio no K8s
```yaml
- apiGroups: [""]
  resources: ["namespaces", "pods"]
  verbs: ["get", "list"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets", "statefulsets", "daemonsets"]
  verbs: ["get", "list"]
- apiGroups: ["autoscaling"]
  resources: ["horizontalpodautoscalers"]
  verbs: ["get", "list"]
- apiGroups: ["metrics.k8s.io"]
  resources: ["pods", "nodes"]
  verbs: ["get", "list"]
```

**ObservaÃ§Ã£o**: Todas as operaÃ§Ãµes sÃ£o somente leitura. Nenhuma permissÃ£o de escrita/modificaÃ§Ã£o Ã© necessÃ¡ria.

## Metas de Desempenho

- **Tempo de varredura**: <5s por cluster (50 HPAs, 10 namespaces)
- **Uso de memÃ³ria**: <100 MB (5 clusters, 250 HPAs, histÃ³rico de 5min)
- **Uso de CPU**: <5% em idle
- **SincronizaÃ§Ã£o com Alertmanager**: Intervalo de 30s
- **AtualizaÃ§Ã£o da TUI**: 500ms

## Status do Roadmap

### Fase 1: FundaÃ§Ã£o âœ… (ConcluÃ­da)
- âœ… Setup e estrutura do projeto
- âœ… Modelos de dados (HPASnapshot, TimeSeriesData, HPAStats)
- âœ… Armazenamento em memÃ³ria com estatÃ­sticas
- âœ… Detector de anomalias (5 anomalias crÃ­ticas)
- âœ… Testes unitÃ¡rios abrangentes (storage + analyzer)
- âœ… DocumentaÃ§Ã£o (README para cada pacote)

### Fase 2: IntegraÃ§Ã£o âœ… (ConcluÃ­da)
- âœ… IntegraÃ§Ã£o com cliente K8s (`monitor/k8s_client.go`)
- âœ… IntegraÃ§Ã£o com cliente Prometheus (`prometheus/client.go`)
- âš ï¸ IntegraÃ§Ã£o com Alertmanager (TODO - nÃ£o crÃ­tico para o MVP)
- âœ… Coletor unificado (`monitor/collector.go`)
- âœ… ImplementaÃ§Ã£o do loop de monitoramento com canais
- âœ… Sistema de configuraÃ§Ã£o com suporte YAML (`config/loader.go`)
- âœ… Todos os testes aprovados (analyzer, storage, monitor, prometheus)

### Fase 3: Interface do UsuÃ¡rio (Atual)
- ğŸ”„ TUI bÃ¡sica (Bubble Tea)
- ğŸ”„ VisÃ£o de dashboard (overview multi-cluster)
- ğŸ”„ VisÃ£o de alertas (com filtragem)
- ğŸ”„ VisÃ£o detalhada de cluster
- ğŸ”„ GrÃ¡ficos ASCII para mÃ©tricas
- ğŸ”„ Modal de configuraÃ§Ã£o
- ğŸ”„ IntegraÃ§Ã£o com canais do coletor

### Fase 4: Recursos AvanÃ§ados
- ğŸ”„ Motor de correlaÃ§Ã£o de alertas
- ğŸ”„ GestÃ£o de silÃªncios via TUI
- ğŸ”„ DetecÃ§Ã£o de anomalias aprimorada (anomalias da Fase 2)
- ğŸ”„ PersistÃªncia SQLite (opcional)
- ğŸ”„ Descoberta automÃ¡tica (clusters, Prometheus, Alertmanager)

### Fase 5: Pronto para ProduÃ§Ã£o
- ğŸ”„ Arquivo de serviÃ§o systemd
- ğŸ”„ Imagem Docker
- ğŸ”„ NotificaÃ§Ãµes via webhook (Slack, Discord, Teams)
- ğŸ”„ OtimizaÃ§Ã£o de performance
- ğŸ”„ Testes de integraÃ§Ã£o
- ğŸ”„ Pipeline de CI/CD

## PadrÃµes Comuns

### Adicionando um Novo Tipo de Anomalia
1. Adicione a constante de tipo de anomalia em `internal/analyzer/detector.go` (`AnomalyType`)
2. Adicione a configuraÃ§Ã£o de threshold na struct `DetectorConfig`
3. Implemente o mÃ©todo de detecÃ§Ã£o (ex.: `detectNewAnomaly()`)
4. Chame o mÃ©todo de detecÃ§Ã£o no loop `Detect()`
5. Adicione testes unitÃ¡rios em `internal/analyzer/detector_test.go`
6. Atualize o README com os detalhes da nova anomalia

### Adicionando uma Nova Consulta Prometheus
1. Defina o template da consulta em `internal/prometheus/queries.go`
2. Adicione a lÃ³gica de parsing para o formato do resultado
3. Integre ao coletor em `internal/monitor/collector.go`
4. Atualize o modelo `HPASnapshot` se precisar de um novo campo

### Expandindo Views da TUI
1. Crie o componente em `internal/tui/components/`
2. Implemente os mÃ©todos `Model`, `Update` e `View` do Bubble Tea
3. Integre no app principal em `internal/tui/app.go`
4. Adicione handlers de teclado em `internal/tui/handlers.go`
5. Defina estilos em `internal/tui/styles.go`

## IntegraÃ§Ã£o com k8s-hpa-manager

Embora o HPA Watchdog possa compartilhar cÃ³digo utilitÃ¡rio com o projeto k8s-hpa-manager (descoberta de clusters, wrappers do cliente K8s), ele Ã© **completamente autÃ´nomo**:
- BinÃ¡rio separado: `hpa-watchdog`
- DiretÃ³rio de configuraÃ§Ã£o separado: `~/.hpa-watchdog/`
- OperaÃ§Ã£o independente (nÃ£o exige que o k8s-hpa-manager esteja rodando)
- Pode rodar como daemon em background ou TUI interativa

## SoluÃ§Ã£o de Problemas

### Problemas de ConexÃ£o com o Prometheus
- Verifique o endpoint: `kubectl port-forward -n monitoring svc/prometheus 9090:9090`
- Cheque os padrÃµes de descoberta automÃ¡tica na configuraÃ§Ã£o
- Habilite o fallback para metrics-server: `prometheus.fallback_to_metrics_server: true`

### MÃ©tricas Ausentes
- Garanta que o Prometheus estÃ¡ coletando kube-state-metrics
- Verifique se o metrics-server estÃ¡ instalado: `kubectl top pods`
- Confirme que as mÃ©tricas alvo do HPA estÃ£o expostas

### Alto Uso de MemÃ³ria
- Reduza `history_retention_minutes` (padrÃ£o: 5)
- Limite `max_active_alerts` (padrÃ£o: 100)
- Desabilite a persistÃªncia se nÃ£o for necessÃ¡ria

### Problemas de SincronizaÃ§Ã£o com o Alertmanager
- Verifique a acessibilidade do endpoint do Alertmanager
- Cheque os filtros de labels dos alertas: `filters.only_hpa_related: true`
- Aumente o intervalo de sync se houver rate-limiting
- "As mensagens de commit devem ser sempre em pt-br"
- "O claude.md deve ser sempre em pt-br"
