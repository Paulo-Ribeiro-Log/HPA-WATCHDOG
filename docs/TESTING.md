# Guia de Testes - HPA Watchdog

Este documento explica como testar o HPA Watchdog em um cluster/namespace/deployment especÃ­fico.

## Comando `test`

O comando `test` permite testar a conectividade e coleta de mÃ©tricas de forma focada em um HPA especÃ­fico.

### Uso BÃ¡sico

```bash
# Testar todos HPAs de um namespace
./build/hpa-watchdog test --cluster production --namespace default

# Testar HPA especÃ­fico
./build/hpa-watchdog test --cluster production --namespace default --hpa my-app

# Com mÃ©tricas do Prometheus
./build/hpa-watchdog test --cluster production --namespace default --prometheus

# Mostrar histÃ³rico de 5 minutos
./build/hpa-watchdog test --cluster production --namespace default --history
```

### Flags DisponÃ­veis

| Flag | AbreviaÃ§Ã£o | DescriÃ§Ã£o | ObrigatÃ³rio |
|------|------------|-----------|-------------|
| `--cluster` | `-c` | Context do kubeconfig | âœ… Sim |
| `--namespace` | `-n` | Namespace do HPA | âœ… Sim |
| `--hpa` | `-H` | Nome do HPA (testa todos se vazio) | âŒ NÃ£o |
| `--prometheus` | `-p` | Coletar mÃ©tricas do Prometheus | âŒ NÃ£o |
| `--history` | (sem abr.) | Mostrar histÃ³rico de 5 minutos | âŒ NÃ£o |
| `--verbose` | `-v` | Logs verbosos | âŒ NÃ£o |
| `--debug` | | Debug mode (global) | âŒ NÃ£o |

### VariÃ¡veis de Ambiente

Alternativamente, vocÃª pode configurar via variÃ¡veis de ambiente:

```bash
# Configurar target
export TEST_CLUSTER_CONTEXT=production
export TEST_NAMESPACE=default
export TEST_HPA_NAME=my-app

# Prometheus
export PROMETHEUS_NAMESPACE=monitoring
export PROMETHEUS_SERVICE=prometheus-server
export USE_PORT_FORWARD=true
export LOCAL_PORT=55553

# Comportamento
export COLLECT_METRICS=true
export SHOW_HISTORY=true
export VERBOSE=true

# Executar
./build/hpa-watchdog test
```

## Exemplos PrÃ¡ticos

### 1. Teste BÃ¡sico (SÃ³ K8s API)

Testa conectividade e coleta dados bÃ¡sicos do HPA:

```bash
./build/hpa-watchdog test \
  --cluster akspriv-faturamento-prd-admin \
  --namespace ingress-nginx \
  --hpa nginx-ingress-controller
```

**Output (com logs filtrados):**
```
ğŸ§ª HPA Watchdog - Teste Integrado
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Cluster:    akspriv-faturamento-prd-admin
   Namespace:  ingress-nginx
   HPA:        nginx-ingress-controller
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Cluster conectado

âœ… 1 HPA(s) encontrado(s)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š HPA 1/1
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ Nome: ingress-nginx/nginx-ingress-controller
ğŸ• Timestamp: 2025-10-24 23:12:37

âš™ï¸  ConfiguraÃ§Ã£o:
   Min/Max Replicas:  3 / 20
   CPU Target:        60%

ğŸ“Š Status Atual:
   Current Replicas:  3
   Desired Replicas:  3
   Ready:             true
   Scaling Active:    true
   Last Scale:        2025-03-20 00:10:46 (7mo ago)

ğŸ’¾ Resources (por pod):
   CPU Request:       384m
   CPU Limit:         512m
   Memory Request:    256Mi
   Memory Limit:      384Mi

ğŸ” AnÃ¡lise RÃ¡pida:
   ğŸŸ¡ CONFIG: Memory target nÃ£o configurado

âœ… Teste concluÃ­do com sucesso!
```

**Dica:** Para remover os logs do stderr e ver apenas a saÃ­da limpa:
```bash
./build/hpa-watchdog test --cluster akspriv-faturamento-prd-admin --namespace ingress-nginx --hpa nginx-ingress-controller 2>/dev/null
```

### 2. Teste com Prometheus

Coleta mÃ©tricas completas via Prometheus:

```bash
./build/hpa-watchdog test \
  --cluster my-cluster \
  --namespace production \
  --hpa my-app \
  --prometheus
```

**Output esperado:**
```
ğŸ§ª Testing HPA Monitoring
   Cluster:    my-cluster
   Namespace:  production
   HPA:        my-app
   Prometheus: enabled

{"level":"info","time":"...","message":"Setting up Prometheus..."}
{"level":"info","local_port":55553,"time":"...","message":"PortForward manager initialized"}
{"level":"info","cluster":"my-cluster","namespace":"monitoring","service":"prometheus-server","local_port":55553,"remote_port":9090,"time":"...","message":"Port-forward started"}
{"level":"info","endpoint":"http://localhost:55553","time":"...","message":"âœ… Prometheus connection OK"}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š HPA: production/my-app
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”¢ Replicas:
   Min/Max:        2 / 10
   Current:        3
   Desired:        3

ğŸ“ˆ Current Metrics (Prometheus):
   CPU:            68.50%
   Memory:         72.30%

ğŸŒ Application Metrics:
   Request Rate:   150.25 req/s
   Error Rate:     0.15%
   P95 Latency:    45.20 ms

âœ… Status:
   Ready:          true
   Scaling Active: true
```

### 3. Teste com HistÃ³rico

Mostra histÃ³rico de 5 minutos:

```bash
./build/hpa-watchdog test \
  --cluster my-cluster \
  --namespace production \
  --hpa my-app \
  --prometheus \
  --history
```

**Output adicional:**
```
ğŸ“Š CPU History (last 5min):
   T-300s: 65.20%
   T-270s: 66.80%
   T-240s: 68.50%
   T-210s: 70.10%
   T-180s: 71.20%
   T-150s: 69.50%
   T-120s: 68.30%
   T-90s:  67.80%
   T-60s:  68.10%
   T-30s:  68.50%

ğŸ“Š Replica History (last 5min):
   T-300s: 3
   T-270s: 3
   T-240s: 3
   T-210s: 3
   T-180s: 3
   T-150s: 3
   T-120s: 3
   T-90s:  3
   T-60s:  3
   T-30s:  3
```

### 4. Teste Todos HPAs de um Namespace

```bash
./build/hpa-watchdog test \
  --cluster my-cluster \
  --namespace production \
  --prometheus
```

Isso testarÃ¡ todos os HPAs encontrados no namespace `production`.

## ConfiguraÃ§Ã£o de Clusters

### Verificar clusters disponÃ­veis

```bash
./build/hpa-watchdog clusters
```

Output:
```
ğŸ“Š Found 3 cluster(s):

1. production (default)
   Context:   production-context
   Server:    https://k8s-prod.example.com

2. staging
   Context:   staging-context
   Server:    https://k8s-stg.example.com

3. development
   Context:   dev-context
   Server:    https://k8s-dev.example.com
```

## Troubleshooting

### Erro: cluster context nÃ£o encontrado

```
âŒ Failed to create K8s client: failed to create client config for cluster production: context "production" does not exist
```

**SoluÃ§Ã£o:**
```bash
# Verificar contexts disponÃ­veis
kubectl config get-contexts

# Usar o context correto
./build/hpa-watchdog test --cluster <context-name> --namespace default
```

### Erro: namespace nÃ£o existe

```
âŒ Failed to list HPAs: namespaces "production" not found
```

**SoluÃ§Ã£o:**
```bash
# Verificar namespaces disponÃ­veis
kubectl get namespaces

# Usar namespace correto
./build/hpa-watchdog test --cluster my-cluster --namespace <existing-namespace>
```

### Erro: HPA nÃ£o encontrado

```
âŒ HPA my-app not found in namespace production
```

**SoluÃ§Ã£o:**
```bash
# Listar HPAs disponÃ­veis
kubectl get hpa -n production

# Usar nome correto ou omitir --hpa para testar todos
./build/hpa-watchdog test --cluster my-cluster --namespace production
```

### Prometheus nÃ£o disponÃ­vel

```
âš ï¸  Failed to setup port-forward, skipping Prometheus
```

**SoluÃ§Ãµes:**

1. Verificar se Prometheus estÃ¡ rodando:
```bash
kubectl get pods -n monitoring | grep prometheus
```

2. Verificar serviÃ§o:
```bash
kubectl get svc -n monitoring | grep prometheus
```

3. Configurar manualmente:
```bash
export PROMETHEUS_NAMESPACE=kube-prometheus
export PROMETHEUS_SERVICE=kube-prometheus-stack-prometheus
./build/hpa-watchdog test --cluster my-cluster --namespace production --prometheus
```

4. Testar port-forward manual:
```bash
kubectl port-forward -n monitoring svc/prometheus-server 9090:9090
curl http://localhost:9090/api/v1/query?query=up
```

### Port 55553 em uso

```
âŒ Failed to start port-forward: bind: address already in use
```

**SoluÃ§Ã£o:**
```bash
# Verificar o que estÃ¡ usando a porta
lsof -i :55553

# Matar processo
kill <PID>

# Ou usar porta diferente
export LOCAL_PORT=55554
./build/hpa-watchdog test --cluster my-cluster --namespace production --prometheus
```

## Scripts de Teste RÃ¡pido

### test-local.sh

Crie um script para testes rÃ¡pidos:

```bash
#!/bin/bash
# test-local.sh

export TEST_CLUSTER_CONTEXT=minikube
export TEST_NAMESPACE=default
export COLLECT_METRICS=true
export SHOW_HISTORY=true
export VERBOSE=true

./build/hpa-watchdog test
```

### test-production.sh

```bash
#!/bin/bash
# test-production.sh

./build/hpa-watchdog test \
  --cluster production \
  --namespace production \
  --hpa api-gateway \
  --prometheus \
  --history \
  --verbose
```

## IntegraÃ§Ã£o com CI/CD

### GitHub Actions

```yaml
name: Test HPA Monitoring
on: [push]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Setup kubectl
        uses: azure/setup-kubectl@v1

      - name: Configure kubeconfig
        run: |
          echo "${{ secrets.KUBECONFIG }}" > kubeconfig
          export KUBECONFIG=./kubeconfig

      - name: Build
        run: make build

      - name: Test HPA Monitoring
        run: |
          ./build/hpa-watchdog test \
            --cluster staging \
            --namespace default \
            --prometheus
```

## MÃ©tricas Coletadas

O comando `test` coleta e exibe as seguintes mÃ©tricas:

### Do Kubernetes API:
- Min/Max replicas
- Current/Desired replicas
- CPU/Memory targets
- Resource requests/limits
- Status (Ready, Scaling Active)
- Last scale time

### Do Prometheus (com --prometheus):
- CPU usage atual (%)
- Memory usage atual (%)
- CPU history (5min, 10 pontos)
- Memory history (5min, 10 pontos)
- Replica history (5min, 10 pontos)
- Request rate (req/s)
- Error rate (%)
- P95 latency (ms)

## AnÃ¡lise RÃ¡pida de Anomalias

O comando `test` inclui anÃ¡lise automÃ¡tica de anomalias comuns. Veja exemplos de detecÃ§Ã£o:

### Anomalias Detectadas

#### 1. Maxed Out (ğŸ”´ CrÃ­tico)
HPA no limite mÃ¡ximo de rÃ©plicas com CPU acima do target:
```
ğŸ” AnÃ¡lise RÃ¡pida:
   ğŸ”´ MAXED OUT: no limite (20) com CPU 85.23% (target: 60%)
```
**AÃ§Ã£o:** Aumentar `maxReplicas` ou verificar capacidade do cluster

#### 2. Underutilization (ğŸŸ¡ Warning)
CPU muito abaixo do target com muitas rÃ©plicas:
```
ğŸ” AnÃ¡lise RÃ¡pida:
   ğŸŸ¡ UNDERUTILIZED: CPU 15.30% muito abaixo do target 60%
```
**AÃ§Ã£o:** Reduzir `minReplicas` ou ajustar target

#### 3. Missing Memory Target (ğŸŸ¡ Config)
HPA sem memory target configurado:
```
ğŸ” AnÃ¡lise RÃ¡pida:
   ğŸŸ¡ CONFIG: Memory target nÃ£o configurado
```
**AÃ§Ã£o:** Adicionar `memory` target ao HPA para autoscaling mais preciso

#### 4. High Error Rate (ğŸ”´ CrÃ­tico)
Taxa de erros 5xx acima de 5%:
```
ğŸ” AnÃ¡lise RÃ¡pida:
   ğŸ”´ HIGH ERROR RATE: 8.45% (crÃ­tico >5%)
```
**AÃ§Ã£o:** Investigar causa dos erros, considerar scale up

#### 5. High Latency (ğŸ”´ CrÃ­tico)
P95 latency acima de 1000ms:
```
ğŸ” AnÃ¡lise RÃ¡pida:
   ğŸ”´ HIGH LATENCY: P95 1523.45ms (>1000ms)
```
**AÃ§Ã£o:** Scale up ou investigar gargalos da aplicaÃ§Ã£o

#### 6. Oscillation (ğŸ”´ CrÃ­tico)
RÃ©plicas mudando frequentemente (>3 vezes em 5min):
```
ğŸ” AnÃ¡lise RÃ¡pida:
   ğŸ”´ OSCILLATION: 5 mudanÃ§as de rÃ©plicas em 5min
```
**AÃ§Ã£o:** Aumentar `stabilizationWindow` do HPA

### Exemplo de SaÃ­da Completa

```bash
./build/hpa-watchdog test --cluster production --namespace api --hpa gateway --prometheus --history 2>/dev/null
```

**SaÃ­da:**
```
ğŸ“Š HPA 1/1
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ Nome: api/gateway
ğŸ• Timestamp: 2025-10-24 23:30:45

âš™ï¸  ConfiguraÃ§Ã£o:
   Min/Max Replicas:  2 / 20
   CPU Target:        70%
   Memory Target:     80%

ğŸ“Š Status Atual:
   Current Replicas:  20
   Desired Replicas:  20
   Ready:             true
   Scaling Active:    true
   Last Scale:        2025-10-24 23:28:15 (2m ago)

ğŸ’¾ Resources (por pod):
   CPU Request:       500m
   CPU Limit:         1000m
   Memory Request:    512Mi
   Memory Limit:      1Gi

ğŸ“ˆ MÃ©tricas (Prometheus):
   CPU Atual:         92.45% (target: 70%, desvio: +22.45%)
   Memory Atual:      75.20% (target: 80%, desvio: -4.80%)

ğŸŒ MÃ©tricas Estendidas:
   Request Rate:      1524.30 req/s
   Error Rate:        8.75%
   P95 Latency:       1845.23 ms

ğŸ“Š HistÃ³rico CPU (5 min):
   T-300s: 68.23%
   T-270s: 72.45%
   T-240s: 78.90%
   T-210s: 85.12%
   T-180s: 88.56%
   T-150s: 90.23%
   T-120s: 91.78%
   T-90s: 92.10%
   T-60s: 92.35%
   T-30s: 92.45%

ğŸ“Š HistÃ³rico Replicas (5 min):
   T-300s: 12
   T-270s: 14
   T-240s: 16
   T-210s: 18
   T-180s: 18
   T-150s: 19
   T-120s: 20
   T-90s: 20
   T-60s: 20
   T-30s: 20

ğŸ” AnÃ¡lise RÃ¡pida:
   ğŸ”´ MAXED OUT: no limite (20) com CPU 92.45% (target: 70%)
   ğŸ”´ HIGH ERROR RATE: 8.75% (crÃ­tico >5%)
   ğŸ”´ HIGH LATENCY: P95 1845.23ms (>1000ms)
```

**InterpretaÃ§Ã£o:**
- HPA estÃ¡ no limite e nÃ£o consegue escalar mais
- Alta carga (CPU 92%, crescendo consistentemente)
- DegradaÃ§Ã£o de performance (erros 8.75%, latÃªncia >1.8s)
- **AÃ§Ã£o urgente:** Aumentar `maxReplicas` ou adicionar capacidade ao cluster

## PrÃ³ximos Passos

ApÃ³s validar que o teste funciona:

1. Execute o watchdog completo:
```bash
./build/hpa-watchdog
```

2. Configure thresholds personalizados em `configs/watchdog.yaml`

3. Configure alertas customizados

4. Integre com Alertmanager para alertas centralizados
